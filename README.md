# FAST: FrAme-multiplexed SpatioTemporal Learning Strategy
<p align="center">
  <img src="./FAST_logo.png" alt="FAST Logo" width="600"/>

![Python](https://img.shields.io/badge/Python-3.9-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

FAST is a real-time self-supervised denoising framework for fluorescence neural imaging, achieving enhanced image quality in low-SNR scenarios through spatiotemporal joint optimization. (https://doi.org/10.21203/rs.3.rs-6101322/v1)

## âœ¨ Key Features

- ğŸš€ **Real-Time Processing**: >1000 fps denoising (hardware-dependent)
- ğŸ¤– **Self-Supervised Learning**: Eliminates need for clean ground truth
- ğŸ”„ **Spatiotemporal Optimization**: Frame-multiplexing enhances SNR
- ğŸ“Š **High Adaptability**: Suitable for various fluorescence imaging data

## ğŸ›  Installation

### Requirements
- Python 3.9+
- PyTorch 2.x (CUDA version aligned with your hardware)
- CUDA-capable GPU (recommended)

### Quick Setup
```bash
# Create and activate environment
conda env create -f environment.yml
conda activate FAST
```

## ğŸš€ Quick Start

### Command Line Mode
```bash
# Training mode
python main.py --config_path "./params.json"

# Testing mode (with pretrained model)
python main.py --config_path "./checkpoint/model_name/config.json" --test_path "./data/test/test_dir"
```

### GUI Mode
```bash
# Launch training GUI
python Train_GUI.py

# Launch testing GUI
python Test_GUI.py
```

## ğŸ“ Directory Structure
```
FAST/
â”œâ”€â”€ checkpoint/         # Model checkpoints
â”‚   â””â”€â”€ model_name
â”œâ”€â”€ data/              # Data directory
â”‚   â”œâ”€â”€ test/          # Testing data
â”‚   â””â”€â”€ train/         # Training data
â”œâ”€â”€ datasets/          # Dataset processing
â”‚   â”œâ”€â”€ dataAug.py     # Data augmentation
â”‚   â”œâ”€â”€ data_process.py
â”‚   â””â”€â”€ dataset.py     # Dataset classes
â”œâ”€â”€ environment.yml    # Environment configuration
â”œâ”€â”€ FAST_logo.png     # Project logo
â”œâ”€â”€ log.txt           # Runtime logs
â”œâ”€â”€ main.py           # Main entry point
â”œâ”€â”€ models/           # Model architectures
â”‚   â”œâ”€â”€ baseLayers.py
â”‚   â”œâ”€â”€ loss/         # Loss functions
â”‚   â”‚   â””â”€â”€ loss.py
â”‚   â””â”€â”€ Unet_Lite.py  # Main model
â”œâ”€â”€ params.json       # Configuration file
â”œâ”€â”€ result/           # Output results
â”‚   â””â”€â”€ model_name
â”œâ”€â”€ Test_GUI.py       # GUI for testing
â”œâ”€â”€ test_in_gui.py
â”œâ”€â”€ test.py          # Testing script
â”œâ”€â”€ Train_GUI.py      # GUI for training
â”œâ”€â”€ train_in_gui.py
â”œâ”€â”€ train.py         # Training script
â””â”€â”€ utils/           # Utility functions
    â”œâ”€â”€ config.py    # Configuration utils
    â”œâ”€â”€ fileSplit.py
    â”œâ”€â”€ general.py   # General utilities
    â””â”€â”€ __init__.py
```

## âš™ï¸ Configuration

Customize model parameters by modifying `params.json`:

```json
{
    "data_extension": "tif",
    "epochs": 100,
    "miniBatch_size": 4,
    "lr": 0.0001,
    "weight_decay": 0.9,
    "gpu_ids": "0",
    "train_frames": 2000,
    "data_type": "3D",
    "denoising_strategy": "FAST",
    "seed": 123,
    "save_freq": 25,
    "clip_gradients": 20.0,
    "num_workers": 0,
    "batch_size": 1
}
```

## ğŸ¤ Contributing

We welcome contributions, particularly:

1. ğŸ› Bug reports and fixes
2. âœ¨ New feature proposals and implementations
3. ğŸ“š Documentation improvements
4. ğŸ¨ Code optimizations

### Coding Standards
- Use `UpperCamelCase` for class names
- Use `lowercase_with_underscores` for functions and variables
- Include docstrings for core functions
- Follow PEP8 standards (validate using `flake8`)

## ğŸ“„ License

This project is licensed under the **GNU General Public License v3.0**. This means you are free to:

- âœ… Use
- âœ… Modify
- âœ… Distribute

But you must:
- âš ï¸ Disclose source
- âš ï¸ Include original copyright
- âš ï¸ Use the same license

See [LICENSE](LICENSE) file for full text.

## â“ FAQ

<details>
<summary>Coming soon</summary>

</details>



## ğŸ“® Contact

- ğŸ“§ Email: yiqunwang22@fudan.edu.cn
- ğŸŒ Project Page: [GitHub Repository](https://github.com/FDU-donglab/FAST)

---

### Citation

If you use FAST in your research, please cite our paper:

```bibtex
@article{wang2024real,
    title={Real-time self-supervised denoising for high-speed fluorescence neural imaging},
    author={Wang, Yiqun and Others},
    journal={https://doi.org/10.21203/rs.3.rs-6101322/v1},
    year={2025}
}
```
